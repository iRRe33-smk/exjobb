{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import sklearn\n",
    "from sklearn import * \n",
    "from pytorch_v2 import TorchGame\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "import numpy as np\n",
    "import random, math, os\n",
    "\n",
    "params_test = {\n",
    "        \"Horizon\": 3, \"Max_actions_chosen\": 2, \"N_actions_startpoint\": 8, \"I\": .5, \"D\": 5,\n",
    "        \"Players_action_length\": [5, 5], \"Max_optim_iter\": 75, \"Filter_actions\": True,\n",
    "        \"Stochastic_state_update\": True, \"base_params\": \"custom\", \"NumRepsBattle\": 8,\n",
    "        \"DEVICE\": \"cpu\", \"MultiProcess\": False\n",
    "    }\n",
    "\n",
    "game = TorchGame(**params_test)\n",
    "pkl_path = \"saved_runs/smallRun_smallVarXi/History.pkl\"\n",
    "df = pd.read_pickle(pkl_path)\n",
    "df = df.loc[:,:]\n",
    "\n",
    "df.State[0] = game.flatten_var(torch.tensor(game.InitialState.tolist())).numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "techNames = game.TechnologyNames\n",
    "techNames = [\"_\".join([x.capitalize() for x in s.split(\"_\")]) for s in techNames]\n",
    "techNamesFull = [\"Sensor technologies\", \"Collaborative systems\", \"Technologies enabling mobility\", \"Control systems & algorithms\", \"Localisation & mapping\", \"Sensor fusion\",\n",
    "                 \"AI & machine learning\", \"Edge computing\", \"Communications & networking\", \"Energy management\", \"Simulation & modelling\",\n",
    "                 \"Human machine interaction\", \"Cybersecurity\", \"Ethics & regulations\"]\n",
    "\n",
    "techNamesFullBroken = [\"Sensor technologies\", \"Collaborative systems\", \"Technologies \\n enabling mobility\", \"Control systems & \\n algorithms\", \"Localisation & \\n mapping\", \"Sensor fusion\",\n",
    "                 \"AI &\\n machine learning\", \"Edge computing\", \"Communications &\\n networking\", \"Energy management\", \"Simulation &\\n modelling\",\n",
    "                 \"Human machine \\n interaction\", \"Cybersecurity\", \"Ethics &\\n regulations\"]\n",
    "\n",
    "paramNames = [\"$\"+PN.replace(\",\",\", \")+\"$\" for PN in game.ParamNames]\n",
    "paramNames[1] = \"$\\phi, \\psi$\"\n",
    "paramNames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  plot_or_show(fig,fileName, dir=None):\n",
    "    if fileName is not None:\n",
    "        if dir is not None:\n",
    "            path = os.path.join(os.getcwd(),\"figures\", dir, fileName)+\".pdf\"\n",
    "        else:\n",
    "            path = os.path.join(os.getcwd(),\"figures\",  fileName)+\".pdf\"\n",
    "        \n",
    "        print(path)\n",
    "        # with open(path,\"w+\") as f:\n",
    "        plt.savefig(path, format = \"pdf\")\n",
    "    else:\n",
    "        fig.show()\n",
    "        fig.tight_layout(pad=3)\n",
    "        \n",
    "# fig,ax = plt.subplots(1,1)\n",
    "# ax.scatter(np.random.randn(100),np.random.randn(100))\n",
    "# plot_or_show(fig, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "techNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# child_col = []\n",
    "# for n in df.Node_id:\n",
    "#     num_children = len(df[df.Parent_id == n].index)\n",
    "#     child_col.append(num_children)\n",
    "\n",
    "\n",
    "\n",
    "# if (df[\"Reward\"]==0).all():\n",
    "  \n",
    "#     numReps = 100\n",
    "#     states = df[\"State\"]\n",
    "#     states = [game.stack_var(torch.tensor(st, dtype=torch.double)) for st in states.values.tolist()]\n",
    "#     thetas = [game.techToParams(st) for st in states]\n",
    "#     scores = [np.mean([game.SalvoBattleSequential(th).numpy() for _ in range(numReps)]) for th in thetas]\n",
    "#     scores = scores\n",
    "#     print(scores)\n",
    "#     df[\"Reward\"] = scores\n",
    "#     df.to_pickle(pkl_path)\n",
    "# else:\n",
    "#     print(\"df aldready contained scores\")\n",
    "# # df[\"Reward\"] = game.SalvoBattleSequential(game.techToParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.Action[1].shape,\n",
    "    df.State[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.State[0])\n",
    "# tmp = np.concatenate((df.State[0][:,0],df.State[0][:,1]),0)\n",
    "# print(tmp)\n",
    "# print(df.State[13])\n",
    "\n",
    "# df.State[1] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('bmh')\n",
    "# plt.rcParams[\"figure.facecolor\"] = \"D1E2FF\"\n",
    "# plt.rcParams[\"axes.facecolor\"] = \"F2F8FF\"\n",
    "csfont = {'fontname':'Georgia'}\n",
    "hfont = {'fontname':'Helvetica'}\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.serif\"] = [\"Times new roman\"]\n",
    "# display(plt.rcParams.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nParams, nTech = game.PARAMCONVERSIONMATRIX.size()\n",
    "print(nParams, nTech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_grid = np.linspace(-1,12,1000)\n",
    "trl_base = game.TechnologyReadiness(torch.tensor(state_grid)).numpy()\n",
    "\n",
    "plt.plot(state_grid, trl_base)\n",
    "plt.ylabel(\"TRL\")\n",
    "plt.xlabel(\"Cummulative research-progress\")\n",
    "plt.title(\"TRL curve\")\n",
    "plt.savefig(\"figures/TRL/generic_trl.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trl(old_state, new_state, title, fileName = None):\n",
    "    nParams, nTech = game.PARAMCONVERSIONMATRIX.size()\n",
    "    print(nParams, nTech)\n",
    "    \n",
    "\n",
    "    old_state_A = old_state[:nTech]\n",
    "    new_state_A = new_state[:nTech]\n",
    "    \n",
    "    old_trl_A = game.TechnologyReadiness(old_state_A).numpy()\n",
    "    new_trl_A = game.TechnologyReadiness(new_state).numpy()\n",
    "\n",
    "    \n",
    "    old_state_B = old_state[nTech:]\n",
    "    new_state_B = new_state[nTech:]\n",
    "    \n",
    "    old_trl_B = game.TechnologyReadiness(old_state_B).numpy()\n",
    "    new_trl_B = game.TechnologyReadiness(new_state_B).numpy()\n",
    "        \n",
    "    state_grid = np.linspace(-1,12,1000)\n",
    "    trl_base = game.TechnologyReadiness(torch.tensor(state_grid)).numpy()\n",
    "    \n",
    "    \n",
    "    # fig.suptitle(title,  fontsize=\"xx-large\")\n",
    "    for i in range(nTech):\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        fig.set_size_inches(7,4)\n",
    "        k = i\n",
    "        # print(i,j,\"-\",k)\n",
    "        # print(r,c)\n",
    "        ax.plot(state_grid, trl_base)\n",
    "        #otes\n",
    "        ax.scatter(old_state_A[k].numpy(), old_trl_A[k], color=\"blue\", alpha = .5, label =\"Player A previous value\")\n",
    "        ax.scatter(old_state_B[k].numpy(), old_trl_B[k], color=\"red\", alpha = .5, label =\"Player B previous value\")\n",
    "        #nes\n",
    "        ax.scatter(new_state_A[k].numpy(), new_trl_A[k], color=\"blue\", alpha = 1, label =\"Player A new value\")\n",
    "        ax.scatter(new_state_B[k].numpy(), new_trl_B[k], color=\"red\", alpha = 1, label =\"Player B new value\")\n",
    "        ax.set_title(techNamesFull[k])\n",
    "        ax.legend()\n",
    "        ax.set_ylabel(\"TRL\")\n",
    "        ax.set_xlabel(\"Cummulative research progress\")\n",
    "            \n",
    "            \n",
    "            \n",
    "        print(techNamesFull[k])\n",
    "        plot_or_show(fig, fileName+\"_\"+str(i), \"TRL\")\n",
    "    # if fileName is not None:\n",
    "    #     fig.savefig(os.path.join(\"figures\", fileName, \".pdf\"), format = \"pdf\")\n",
    "    # else:\n",
    "    #     fig.show()\n",
    "    #     fig.tight_layout(pad=3)\n",
    "    \n",
    "def plot_act_theta(state, action, state_id, fileName = None):\n",
    "    nParams, nTech = game.PARAMCONVERSIONMATRIX.size()\n",
    "    \n",
    "    action = game.stack_var(action)\n",
    "    theta = game.techToParams(game.stack_var(state))\n",
    "    \n",
    "    theta_A = theta[:,0].numpy()\n",
    "    action_A = action[:,0].numpy()\n",
    "   \n",
    "    theta_B = theta[:,1].numpy()\n",
    "    action_B = action[:,1].numpy()\n",
    "    \n",
    "    fig, axs = plt.subplots(1,2)\n",
    "    fig.set_size_inches(14,4)\n",
    "    # fig.suptitle(title)\n",
    "    \n",
    "    width = .5\n",
    "    r = np.arange(nTech)\n",
    "    axs[0].set_title(f\"Actions of each player in sampled state\")\n",
    "    axs[0].bar(r, action_A, color=\"blue\", width= width, label=\"Player A\")\n",
    "    axs[0].bar(r+width, action_B, color=\"red\", width= width, label=\"Player B\")\n",
    "    # axs[1].xticks(r + width/2 , labels = game.ParamNames)\n",
    "    axs[0].set_xticks(r + width/2)\n",
    "    axs[0].set_xticklabels(labels = techNames)\n",
    "    axs[0].legend()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # width = .5\n",
    "    r = np.arange(nParams)\n",
    "    axs[1].set_title(f\"Battle Parameters of each player in sampled state\")\n",
    "    axs[1].bar(r, theta_A, color=\"blue\", width= width, label=\"Player A\")\n",
    "    axs[1].bar(r+width, theta_B, color=\"red\", width= width, label=\"Player B\")\n",
    "    # axs[1].xticks(r + width/2 , labels = game.ParamNames)\n",
    "    axs[1].set_xticks(r + width/2)\n",
    "    axs[1].set_xticklabels(labels = paramNames)\n",
    "    axs[1].legend()\n",
    "\n",
    "\n",
    "\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    \n",
    "    plot_or_show(fig, fileName, None)\n",
    "    \n",
    "#     if fileName is not None:\n",
    "        \n",
    "#         fig.savefig(os.path.join(\"figures\", fileName, \".pdf\"), format = \"pdf\")\n",
    "#     else:\n",
    "#         fig.show()\n",
    "#         # fig.tight_layout(pad=3)\n",
    "\n",
    "#     # fig.show()\n",
    "    \n",
    "    \n",
    "# # df.Action[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.Node_id == 0].State.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df.columns)\n",
    "numPoints = len(df.index)\n",
    "old_state_i = df.Parent_id\n",
    "states =df.State\n",
    "actions = df.Action\n",
    "\n",
    "plot_ind = 5\n",
    "\n",
    "p_id = df.loc[plot_ind,:].Parent_id\n",
    "print(p_id)\n",
    "old_state =  torch.tensor(df[df.Node_id == p_id].State.values.tolist()).squeeze()\n",
    "\n",
    "new_state =  torch.tensor(states[plot_ind]).squeeze()\n",
    "\n",
    "act = torch.tensor(actions[plot_ind]).squeeze()\n",
    "plot_act_theta(new_state, act, plot_ind, \"actionTheta\")\n",
    "plot_trl(old_state,new_state, \"Technology research progress in one timestep\", \"TRL_onestep\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_nodes = df[df.Time == df.Time.max()].Node_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df.columns)\n",
    "numPoints = len(df.index)\n",
    "old_state_i = df.Parent_id\n",
    "states =df.State\n",
    "actions = df.Action\n",
    "\n",
    "print(leaf_nodes)\n",
    "# plot_ind = df.Node_id.max()\n",
    "\n",
    "p_id = np.random.choice(leaf_nodes)\n",
    "p_id = 29\n",
    "print(p_id) #29, 44\n",
    "old_state =  torch.tensor(df[df.Node_id == 0].State.values.tolist()).squeeze()\n",
    "\n",
    "new_state =  torch.tensor(df[df.Node_id == p_id].State.values.tolist()).squeeze()\n",
    "\n",
    "act = torch.tensor(actions[plot_ind]).squeeze()\n",
    "# plot_act_theta(new_state, act, plot_ind)\n",
    "plot_trl(old_state,new_state, \"Technology research progress throughout full simulation\", \"TRL_fullGame\")\n",
    "\n",
    "# print(old_state)\n",
    "# print(new_state)\n",
    "# print(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(leaf_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (.values.astype(np.float32))\n",
    "\n",
    "acts = torch.tensor(df.Action.dropna().values.tolist())\n",
    "# Vals.shape\n",
    "# Vals[:,game.N_Technologies:]\n",
    "def update_projection(ax, axi, projection='3d', fig=None):\n",
    "    if fig is None:\n",
    "        fig = plt.gcf()\n",
    "    rows, cols, start, stop = axi.get_subplotspec().get_geometry()\n",
    "    ax.flat[start].remove()\n",
    "    ax.flat[start] = fig.add_subplot(rows, cols, start+1, projection=projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num\n",
    "def one_sided_pca_plot(df, key, t_max, fileName = None):\n",
    "    \n",
    "    if t_max:\n",
    "        df = df[df.Time == df.Time.max()]\n",
    "    if key == \"Theta\":\n",
    "        key = \"State\"\n",
    "        theta = True\n",
    "    else: \n",
    "        theta = False\n",
    "    \n",
    "    \n",
    "    \n",
    "    vals = torch.tensor(getattr(df, key).dropna().values.tolist())\n",
    "    numVals = vals.shape[0]\n",
    "    if theta:\n",
    "        thetas = []\n",
    "        for i in range(numVals):\n",
    "            # print(vals.shape)\n",
    "            nTech = int(vals.shape[1] / 2)\n",
    "            \n",
    "            # a = vals[i,:nTech].T\n",
    "            # b = vals[i,nTech:].T\n",
    "            # print(a,b)\n",
    "            state = game.stack_var(vals[i,:])\n",
    "            # print(state)\n",
    "            th = game.techToParams(state).numpy()\n",
    "            thetas.append(th[:,0])            \n",
    "            thetas.append(th[:,1])\n",
    "            allVals = thetas\n",
    "    else:\n",
    "       \n",
    "        valsA, valsB = (vals[:,:game.N_Technologies]).numpy(), (vals[:,game.N_Technologies:]).numpy()\n",
    "        allVals = np.concatenate((valsA,valsB),0)\n",
    "        \n",
    "    \n",
    "    pca = sklearn.decomposition.PCA(3)\n",
    "    pca_fit_AB = pca.fit_transform(allVals)\n",
    "    \n",
    "    pca_fit_A = pca_fit_AB[:numVals,:]\n",
    "    pca_fit_B = pca_fit_AB[numVals:,:]\n",
    "\n",
    "    fig, ax = plt.subplots(1,2,figsize=(16,4), width_ratios=(1,2))\n",
    "    \n",
    "    update_projection(ax,ax.flat[0],\"3d\")\n",
    "    ax1, ax2 = ax\n",
    "    # fix , axs = plt.subplots(1,2,width_ratios=(1,3))\n",
    "    # ax = axs[0]\n",
    "    # if t_max:\n",
    "    #     fig.suptitle(f\"{numVals} {key}s in last time-step\")\n",
    "    # else:\n",
    "    #     fig.suptitle(f\"{numVals} {key}s\")\n",
    "        \n",
    "    # ax = fig.add_subplot(1,2, 1 ,projection='3d')\n",
    "\n",
    "    ax1.scatter(pca_fit_A[:,0], pca_fit_A[:,1], pca_fit_A[:,2], color=\"blue\", label=\"Player A\")\n",
    "    ax1.scatter(pca_fit_B[:,0], pca_fit_B[:,1], pca_fit_B[:,2], color=\"red\", label=\"Player B\")\n",
    "\n",
    "    ax1.set_xlabel('$PC_1$')\n",
    "    ax1.set_ylabel('$PC_2$')\n",
    "    ax1.set_zlabel('$PC_3$')\n",
    "    \n",
    "    # ax1.set_title(f\"{key if  not theta else 'Battle parameter'}s projected onto PC1, PC2, PC3\")\n",
    "    \n",
    "    ax1.legend()\n",
    "    \n",
    "    \n",
    "    components = pca.components_\n",
    "    var = pca.explained_variance_ratio_\n",
    "    \n",
    "    nTech = np.shape(components[0])[0]\n",
    "    nComps = len(components)\n",
    "   \n",
    "    # ax2 = fig.add_subplot(1,2,2 )\n",
    "    # ax2.set_title(f\"{key if  not theta else 'BattleParam'}s, first {nComps} Principal components. \\n explained variance:{np.round(var,2)}\")\n",
    "    \n",
    "   \n",
    "    width = .5\n",
    "    r = np.arange(nTech)\n",
    "    \n",
    "    ax2.bar(r, components[0], color=\"blue\", width=1/5,          label=f\"$PC_1, {round(100 * var[0],1)} \\%$\")\n",
    "    ax2.bar(r + width/2, components[1], color=\"red\", width=1/5, label=f\"$PC_2, {round(100 * var[1],1)} \\%$\")\n",
    "    ax2.bar(r + width, components[2], color=\"green\", width=1/5, label=f\"$PC_3, {round(100 *var[2],1)} \\%$\")\n",
    "    if  theta:\n",
    "        ax2.set_xticks(r + width/2, paramNames, rotation = 45, ha=\"right\", fontsize=12)\n",
    "    else:\n",
    "        ax2.set_xticks(r + width/2, techNames, rotation = 45, ha=\"right\", fontsize=12)\n",
    "    # ax2.set_xticklabels(labels = game.TechnologyNames)\n",
    "    # ax2.set_x\n",
    "    ax2.legend(loc = \"upper left\")\n",
    "    \n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plot_or_show(fig,fileName, None)\n",
    "    # if fileName is not None:\n",
    "    #     fig.savefig(os.path.join(\"figures\", fileName, \".pdf\"), format = \"pdf\")\n",
    "    # else:\n",
    "    #     fig.show()\n",
    "    #     fig.tight_layout(h_pad = 0, pad=0)\n",
    "\n",
    "    \n",
    "\n",
    "one_sided_pca_plot(df, \"Action\",False,\"onesidede_PCA_all_action\")\n",
    "one_sided_pca_plot(df, \"Action\", True, \"onesided_PCA_last_action\")\n",
    "one_sided_pca_plot(df, \"State\", False, \"onesided_PCA_all_state\"  )\n",
    "one_sided_pca_plot(df, \"State\",  True,  \"onesided_PCA_last_state\" )\n",
    "one_sided_pca_plot(df, \"Theta\", False,\"onesided_PCA_all_theta\"  )\n",
    "one_sided_pca_plot(df, \"Theta\",  True, \"onesided_PCA_all_theta\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def two_sided_pca_plot(df, key, t_max, fileName = None):\n",
    "    if t_max:\n",
    "        df = df[df.Time == df.Time.max()]\n",
    "    if key == \"Theta\":\n",
    "        key = \"State\"\n",
    "        theta = True\n",
    "    else: \n",
    "        theta = False\n",
    "        \n",
    "    vals = torch.tensor(getattr(df, key).dropna().values.tolist())\n",
    "    numVals = vals.shape[0]\n",
    "    if theta:\n",
    "        thetas = []\n",
    "        for i in range(numVals):\n",
    "            # print(vals.shape)\n",
    "            nTech = int(vals.shape[1] / 2)\n",
    "            \n",
    "            # a = vals[i,:nTech].T\n",
    "            # b = vals[i,nTech:].T\n",
    "            # print(a,b)\n",
    "            state = game.stack_var(vals[i,:])\n",
    "            # print(state)\n",
    "            th = game.flatten_var(game.techToParams(state)).numpy()\n",
    "            thetas.append(th)            \n",
    "            # thetas.append(th)\n",
    "            allVals = thetas\n",
    "    else:\n",
    "\n",
    "        valsA, valsB = (vals[:,:game.N_Technologies]).numpy(), (vals[:,game.N_Technologies:]).numpy()\n",
    "        allVals = np.concatenate((valsA,valsB),1)\n",
    "        \n",
    "    \n",
    "    pca = sklearn.decomposition.PCA(3)\n",
    "    pca_fit = pca.fit_transform(allVals)\n",
    "    \n",
    "    # pca_fit_A = pca_fit_AB[:numVals,:]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1,2,figsize=(16,4), width_ratios=(1,2))\n",
    "    \n",
    "    update_projection(ax,ax.flat[0],\"3d\")\n",
    "    ax1, ax2 = ax\n",
    "    # fix , axs = plt.subplots(1,2,width_ratios=(1,3))\n",
    "    # ax = axs[0]\n",
    "    # if t_max:\n",
    "    #     fig.suptitle(f\"{numVals} {key}s in last time-step\")\n",
    "    # else:\n",
    "    #     fig.suptitle(f\"{numVals} {key}s\")\n",
    "        \n",
    "    # ax = fig.add_subplot(2,2,1  ,projection='3d')\n",
    "\n",
    "    ax1.scatter(pca_fit[:,0], pca_fit[:,1], pca_fit[:,2], color=\"green\")\n",
    "\n",
    "    ax1.set_xlabel('$PC_1$')\n",
    "    ax1.set_ylabel('$PC_2$')\n",
    "    ax1.set_zlabel('$PC_3$')\n",
    "    \n",
    "    # ax1.set_title(f\"{key if  not theta else 'BattleParams'}s projected onto PC1, PC1, PC3\")\n",
    "    \n",
    "    ax1.legend()\n",
    "    \n",
    "    \n",
    "    components = pca.components_\n",
    "    var = pca.explained_variance_ratio_\n",
    "    \n",
    "    nTech = np.shape(components[0])[0]\n",
    "    nComps = len(components)\n",
    "   \n",
    "    # ax2 = fig.add_subplot(2,4,3 )\n",
    "    # ax2.set_title(f\"{key if  not theta else 'Battle Parameter' }s, first {nComps} Principal components. \\n explained variance:{np.round(var,2)}\")\n",
    "    \n",
    "   \n",
    "    width = .5\n",
    "    r = np.arange(nTech)\n",
    "    \n",
    "    ax2.bar(r, components[0], color=\"blue\", width=1/5,          label=f\"$PC_1, {round(100 * var[0],1)} \\%$\")\n",
    "    ax2.bar(r + width/2, components[1], color=\"red\", width=1/5, label=f\"$PC_2, {round(100 * var[1],1)} \\%$\")\n",
    "    ax2.bar(r + width, components[2], color=\"green\", width=1/5, label=f\"$PC_3, {round(100 *var[2],1)} \\%$\")\n",
    "\n",
    "    if  theta:\n",
    "        ax2.set_xticks(r + width/2, paramNames * 2, rotation = 45, ha=\"right\", fontsize=14)\n",
    "    else:\n",
    "        ax2.set_xticks(r + width/2, techNames * 2, rotation = 45, ha=\"right\", fontsize=12)\n",
    "    # ax2.set_xticklabels(labels = game.TechnologyNames)\n",
    "    # ax2.set_x\n",
    "    ax2.legend()\n",
    "    \n",
    "    \n",
    "    \n",
    "    plot_or_show(fig,fileName, None)\n",
    "    # if fileName is not None:\n",
    "    #     fig.savefig(os.path.join(\"figures\", fileName, \".pdf\"), format = \"pdf\")\n",
    "    # else:\n",
    "    #     fig.show()\n",
    "    #     fig.tight_layout(h_pad = 0, pad=0)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "two_sided_pca_plot(df,\"Action\", False, \"twosided_PCA_all_action\")\n",
    "two_sided_pca_plot(df,\"Action\", True ,\"twosided_PCA_last_action\")\n",
    "two_sided_pca_plot(df,\"State\", False, \"twosided_PCA_all_state\")  \n",
    "two_sided_pca_plot(df,\"State\", True,  \"twosided_PCA_last_state\")\n",
    "two_sided_pca_plot(df, \"Theta\", False,\"twosided_PCA_all_theta\"  )\n",
    "two_sided_pca_plot(df, \"Theta\", True, \"twosided_PCA_all_theta\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = 0 \n",
    "upper = 12\n",
    "numPoints = 20\n",
    "ranges = [np.linspace(lower,upper,numPoints) for _ in range(2*nTech)]\n",
    "# [_ for _ in ranges[0]]\n",
    "# grids = np.mgrid(ranges)\n",
    "\n",
    "# for points in zip(grids):\n",
    "#     print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "lower = 1 \n",
    "upper = 12\n",
    "\n",
    "numPoints = 100\n",
    "nParams = 10\n",
    "numReps = 1\n",
    "for vals in itertools.combinations_with_replacement(range(lower,upper,numPoints),10):\n",
    "    print(vals)\n",
    "    # thetaA = [6] + list(vals[:5]) + [1/3, 1]\n",
    "    # thetaB = [6] + list(vals[5:]) + [1/3, 1]\n",
    "    # theta_list = torch.tensor(thetaA + thetaB)\n",
    "    # print(theta_list)\n",
    "\n",
    "    # theta = torch.stack((theta_list[:8], theta_list[8:]), dim=1).squeeze()\n",
    "    # try:\n",
    "    #     score = np.mean([game.SalvoBattleSequential(theta).numpy() for _ in range(numReps)])\n",
    "    # except AssertionError:\n",
    "    #     score = None\n",
    "    # print(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for vals in itertools.combinations_with_replacement(range(lower,25,numPoints),10):\n",
    "    print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_pca_score(df, fileName = None):\n",
    "    key = \"Theta\"\n",
    "    if key == \"Theta\":\n",
    "        key = \"State\"\n",
    "        theta = True\n",
    "    else: \n",
    "        theta = False\n",
    "        \n",
    "    vals = torch.tensor(getattr(df, key).dropna().values.tolist())\n",
    "    numVals = vals.shape[0]\n",
    "    if theta:\n",
    "        thetas = []\n",
    "        for i in range(numVals):\n",
    "            \n",
    "            \n",
    "            state = game.stack_var(vals[i,:])\n",
    "            # print(state)\n",
    "            th = game.flatten_var(game.techToParams(state)).numpy()\n",
    "            thetas.append(th)            \n",
    "            # thetas.append(th)\n",
    "            allVals = thetas\n",
    "    else:\n",
    "\n",
    "        valsA, valsB = (vals[:,:game.N_Technologies]).numpy(), (vals[:,game.N_Technologies:]).numpy()\n",
    "        allVals = np.concatenate((valsA,valsB),1)\n",
    "        \n",
    "    \n",
    "    pca = sklearn.decomposition.PCA(3)\n",
    "    pca_fit = pca.fit_transform(allVals)\n",
    "    print(len(allVals))\n",
    "    \n",
    "    \n",
    "    scores = df[\"Reward\"].tolist()\n",
    "    hi = max(scores)\n",
    "    lo = min(scores)\n",
    "    # print(hi, lo)\n",
    "    green = np.array([0, 255, 0, 0.75*255])/255\n",
    "    red =  np.array([255, 0, 0, 0.75*255])/255\n",
    "    standardizedScores = [(s-lo)/(hi-lo) for s in scores]\n",
    "    # print(standardizedScores)\n",
    "    colors = [green * ss + red * ( 1 - ss) for ss in standardizedScores ]\n",
    "    # print(colors)\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, axs = plt.subplots(1,1,subplot_kw={\"projection\": \"3d\"}, figsize=(6,6))\n",
    "    # fig.set\n",
    "    # update_projection(axs,axs.flat[0])\n",
    "    # fig.suptitle(f\"low:{round(lo,3)}, high:{round(hi,3)}\")\n",
    "    \n",
    "    # ax = axs[0]\n",
    "    ax = axs\n",
    "    ax.scatter(pca_fit[:,0], pca_fit[:,1], pca_fit[:,2], color = colors)\n",
    "\n",
    "    ax.set_xlabel('$PC_1$')\n",
    "    ax.set_ylabel('$PC_2$')\n",
    "    ax.set_zlabel('$PC_3$')\n",
    "\n",
    "    # fig.colorbar(scores,ax=ax)\n",
    "\n",
    "\n",
    "    plot_or_show(fig,fileName)\n",
    "    \n",
    "    # if fileName is not None:\n",
    "    #     fig.savefig(os.path.join(\"figures\", fileName, \".pdf\"), format = \"pdf\")\n",
    "    # else:\n",
    "    #     fig.show()\n",
    "    #     fig.tight_layout(h_pad = 0, pad=0)\n",
    "    \n",
    "    \n",
    "theta_pca_score(df.loc[1:,:], \"PCA_theta_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_pca_plot(df, key, t_max=False, fileName = None):\n",
    "    if t_max:\n",
    "        df = df[df.Time == df.Time.max()]\n",
    "    if key == \"theta\":\n",
    "        vals = torch.tensor(getattr(df, \"State\").dropna().values.tolist())\n",
    "        thetas = []\n",
    "        for i in range(max(vals.size)):\n",
    "            \n",
    "            \n",
    "            state = game.stack_var(vals[i,:])\n",
    "            # print(state)\n",
    "            th = game.flatten_var(game.techToParams(state)).numpy()\n",
    "            thetas.append(th)            \n",
    "            thetas.append(th)\n",
    "        vals = thetas\n",
    "        vals\n",
    "    else:\n",
    "        \n",
    "        vals = torch.tensor(getattr(df, key).dropna().values.tolist())\n",
    "    \n",
    "        # print(vals)\n",
    "        numVals = vals.shape[0]\n",
    "        valsA, valsB = (vals[:,:game.N_Technologies]).numpy(), (vals[:,game.N_Technologies:]).numpy()\n",
    "\n",
    "    # print(valsA, valsB)\n",
    "    pca = sklearn.decomposition.PCA()\n",
    "    pca_fit_AB = pca.fit_transform(np.concatenate((valsA,valsB),0))\n",
    "    \n",
    "    evr = pca.explained_variance_ratio_\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    # ax.set_title(f\"explained variance of PC, {key}\")\n",
    "    ax.bar(range(pca.n_components_),evr, label=\"per $PC$\")\n",
    "    ax.plot(range(pca.n_components_),np.cumsum(evr), label =\"cummulative sum\")\n",
    "    \n",
    "    ax.set_xlabel(\"$PC_n$\")\n",
    "    ax.set_ylabel(\"explained variance, ratio\")\n",
    "    ax.legend(loc=\"best\")    \n",
    "    print(np.cumsum(evr)[2])\n",
    "    plot_or_show(fig,fileName)\n",
    "    # if fileName is not None:\n",
    "    #     fig.savefig(os.path.join(\"figures\", fileName, \".pdf\"), format = \"pdf\")\n",
    "    # else:\n",
    "    #     fig.show()\n",
    "    #     fig.tight_layout(h_pad = 0, pad=0)\n",
    "\n",
    "all_pca_plot(df, \"Action\", False, \"explained_variance_all_action\")\n",
    "all_pca_plot(df, \"Action\", True, \"explained_variance_last_action\")\n",
    "all_pca_plot(df, \"State\", False, \"explained_variance_all_state\")\n",
    "all_pca_plot(df, \"State\", True, \"explained_variance_last_state\")\n",
    "# all_pca_plot(df, \"Theta\", False)\n",
    "# all_pca_plot(df, \"Theta\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onePlayer_pca_plot(df, key, t_max=False, player = 0, fileName = None):\n",
    "    if t_max:\n",
    "        df = df[df.Time == df.Time.max()]\n",
    "    vals = torch.tensor(getattr(df, key).dropna().values.tolist())\n",
    "    \n",
    "    \n",
    "    # print(vals)\n",
    "    numVals = vals.shape[0]\n",
    "    valsA, valsB = (vals[:,:game.N_Technologies]).numpy(), (vals[:,game.N_Technologies:]).numpy()\n",
    "\n",
    "    # print(valsA, valsB)\n",
    "    pca = sklearn.decomposition.PCA()\n",
    "    # pca_fit_AB = pca.fit_transform(np.concatenate((valsA,valsB),0))\n",
    "    if player == 0:    \n",
    "        pca_fit = pca.fit_transform(valsA,0)\n",
    "    elif player == 1:\n",
    "        pca_fit = pca.fit_transform(valsB,0)\n",
    "    \n",
    "    # pca_fit.explain_variance_raito_\n",
    "    evr = pca.explained_variance_ratio_\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    # ax.set_title(f\"explained variance of PC, {key}\")\n",
    "    ax.bar(range(pca.n_components_),evr, label=\"per $PC$\")\n",
    "    ax.plot(range(pca.n_components_),np.cumsum(evr), label =\"cummulative sum\")\n",
    "    \n",
    "    ax.set_xlabel(\"$PC_n$\")\n",
    "    ax.set_ylabel(\"explained variance, ratio\")\n",
    "    ax.legend(loc=\"best\")    \n",
    "    # ax.axvline(2)\n",
    "    plot_or_show(fig,fileName, \"EXPLAINED_VARIANCE\")\n",
    "    # if fileName is not None:\n",
    "    #     fig.savefig(os.path.join(\"figures\", fileName, \".pdf\"), format = \"pdf\")\n",
    "    # else:\n",
    "    #     fig.show()\n",
    "    #     fig.tight_layout(h_pad = 0, pad=0)\n",
    "\n",
    "# all_pca_plot(df, \"Action\", False,0, \"explained_variance_all_action\")\n",
    "# all_pca_plot(df, \"Action\", True,0 \"explained_variance_last_action\")\n",
    "all_pca_plot(df, \"State\", False, \"explained_variance_all_state\")\n",
    "onePlayer_pca_plot(df, \"State\", False, 0,\"explained_variance_last_state\")\n",
    "onePlayer_pca_plot(df, \"State\", False, 1,\"explained_variance_last_state\")\n",
    "\n",
    "# all_pca_plot(df, \"Theta\", False)\n",
    "# all_pca_plot(df, \"Theta\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Total capital invested normalised\n",
    "Budget = [1,1]\n",
    "nTech\n",
    "actions = torch.tensor(df.Action[1:].values.tolist())\n",
    "actionsA = actions[:,:nTech]\n",
    "actionsB = actions[:,nTech:]\n",
    "\n",
    "meansA = actionsA.mean(dim=0)\n",
    "meansB = actionsB.mean(dim=0)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "# ax2 = fig.add_subplot(1,2,2 )\n",
    "# ax.set_title(f\"Average investment per technology per player\")\n",
    "\n",
    "\n",
    "width = .5\n",
    "r = np.arange(nTech)\n",
    "\n",
    "ax.bar(r - width/3, meansA, color=\"blue\", width=1/3, label=\"Player A\")\n",
    "ax.bar(r + width/3, meansB, color=\"red\", width=1/3, label=\"Player B\")\n",
    "ax.set_xticks(r, techNamesFull, rotation = 45, ha=\"right\")\n",
    "ax.scatter(r,game.PARAMCONVERSIONMATRIX.sum(axis=0)/game.PARAMCONVERSIONMATRIX.sum(axis=0).sum(), color=\"black\", label=\"Share of weights in $C$\")\n",
    "ax.legend()\n",
    "# ax.bar(r + width, components[2], color=\"green\", width=1/5, label=\"PC3\")\n",
    "# if  theta:\n",
    "#     ax2.set_xticks(r + width/2, game.ParamNames * 2, rotation = 45, ha=\"right\")\n",
    "# else:\n",
    "#     ax2.set_xticks(r + width/2, game.TechnologyNames * 2, rotation = 45, ha=\"right\")\n",
    "# ax2.set_xticklabels(labels = game.TechnologyNames)\n",
    "# ax2.set_x\n",
    "# ax2.legend()\n",
    "\n",
    "\n",
    "plot_or_show(fig,\"average_investment_technologies\")\n",
    "# fig.tight_layout(h_pad = 0, pad=0)\n",
    "# fig.show()\n",
    "# fig.savefig(os.path.join(\"figures\", \"average_investment_technologies\", \".pdf\"), format = \"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Total capital invested normalised\n",
    "Budget = [1,1]\n",
    "C = game.PARAMCONVERSIONMATRIX\n",
    "C_comp = game.PARAMCONVERSIONMATRIX.sum(axis=1)/game.PARAMCONVERSIONMATRIX.sum()\n",
    "\n",
    "actions = torch.tensor(df.Action[1:].values.tolist(),dtype=torch.double)\n",
    "\n",
    "actionsA = actions[:,:nTech]\n",
    "actionsB = actions[:,nTech:]\n",
    "\n",
    "deltaThetaA = C @ actionsA.T\n",
    "deltaThetaB = C @ actionsB.T\n",
    "# print(deltaThetaA.size())\n",
    "\n",
    "deltaThetaA_means = deltaThetaA.mean(dim=1)\n",
    "deltaThetaA_means = deltaThetaA_means / deltaThetaA_means.sum()\n",
    "deltaThetaB_means = deltaThetaB.mean(dim=1)\n",
    "deltaThetaB_means = deltaThetaB_means / deltaThetaB_means.sum()\n",
    "\n",
    "# meansA = actionsA.mean(dim=0)\n",
    "# meansB = actionsB.mean(dim=0)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "# ax2 = fig.add_subplot(1,2,2 )\n",
    "# ax.set_title(f\"Average parameter impact of investments  per player\")\n",
    "\n",
    "\n",
    "width = .5\n",
    "r = np.arange(len(paramNames))\n",
    "\n",
    "ax.bar(r - width/3, deltaThetaA_means, color=\"blue\", width=1/3, label=\"Player A\")\n",
    "ax.bar(r + width/3, deltaThetaB_means, color=\"red\", width=1/3, label=\"Player B\")\n",
    "ax.set_xticks(r, paramNames, rotation = 45, ha=\"right\", fontsize=14)\n",
    "ax.scatter(r,C_comp, color=\"black\", label=\"Share of weights in $C$\")\n",
    "ax.legend()\n",
    "# ax.bar(r + width, components[2], color=\"green\", width=1/5, label=\"PC3\")\n",
    "# if  theta:\n",
    "#     ax2.set_xticks(r + width/2, game.ParamNames * 2, rotation = 45, ha=\"right\")\n",
    "# else:\n",
    "#     ax2.set_xticks(r + width/2, game.TechnologyNames * 2, rotation = 45, ha=\"right\")\n",
    "# ax2.set_xticklabels(labels = game.TechnologyNames)\n",
    "# ax2.set_x\n",
    "# ax2.legend()\n",
    "\n",
    "\n",
    "fig.tight_layout(h_pad = 0, pad=0)\n",
    "# fig.show()\n",
    "plot_or_show(fig,\"average_investment_params\")\n",
    "# fig.savefig(os.path.join(\"figures\", \"average_investment_params\", \".pdf\"), format = \"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(deltaThetaB_means, \"\\n\",\n",
    "    paramNames)\n",
    "print(nParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = []\n",
    "pca = sklearn.decomposition.PCA(3)\n",
    "vals = torch.tensor(getattr(df, \"State\").dropna().values.tolist())\n",
    "valsA, valsB = (vals[:,:game.N_Technologies]).numpy(), (vals[:,game.N_Technologies:]).numpy()\n",
    "allVals = np.concatenate((valsA,valsB),0)\n",
    "# print(allVals.shape)\n",
    "pca.fit(allVals)\n",
    "states_A_pca = pca.transform(valsA)\n",
    "states_B_pca = pca.transform(valsB)\n",
    "\n",
    "# pca_fit = pca.fit_transform(allVals)\n",
    "\n",
    "def get_trajectory(df, node_id):\n",
    "    node_ids = [node_id]\n",
    "\n",
    "    while node_id  != 0:\n",
    "        node_id = int(df[df.Node_id == node_id].Parent_id.values[0])\n",
    "        node_ids.append(node_id)\n",
    "    # node_ids.append(0)\n",
    "    return node_ids\n",
    "\n",
    "leaf_nodes = df[df.Time == df.Time.max()].Node_id.values.tolist()\n",
    "leaf_nodes\n",
    "trajectories = []\n",
    "for l_id in leaf_nodes:\n",
    "    traj =  get_trajectory(df, node_id=l_id)\n",
    "    # print(traj)\n",
    "    trajectories.append(traj)\n",
    "    \n",
    "states = torch.Tensor(df[df.Node_id.isin(traj)].State.values.tolist())\n",
    "# print(states.shape)\n",
    "# statesA = states[:,:nTech].numpy()\n",
    "# statesB = states[:,nTech:].numpy()\n",
    "# statesA = pca.transform(statesA).tolist()\n",
    "# statesB = pca.transform(statesB).tolist()\n",
    "\n",
    "numPlots = min(len(trajectories),15)\n",
    "\n",
    "\n",
    "sample_idx = random.sample(range(len(trajectories)),numPlots)\n",
    "print(sample_idx)\n",
    "for i in range(numPlots):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(6,6), subplot_kw= {\"projection\" : \"3d\"})\n",
    "    idx = sample_idx[i]\n",
    "    print(idx)\n",
    "    traj = trajectories[idx]\n",
    "\n",
    "    # iterating over grid\n",
    "\n",
    "    ax.set_xlabel('$PC_1$')\n",
    "    ax.set_ylabel('$PC_2$')\n",
    "    ax.set_zlabel('$PC_3$')\n",
    "\n",
    "    # ax.set_xlim3d((-25,25))\n",
    "    # ax.set_ylim3d((-100,100))\n",
    "    # ax.set_zlim3d((-50,50))    \n",
    "\n",
    "    print(traj)\n",
    "    states_A_pca_traj = states_A_pca[traj]\n",
    "    states_B_pca_traj = states_B_pca[traj]\n",
    "    # print(states_B_pca_traj)\n",
    "    # print(states_A_pca_traj)\n",
    "    # print(states_A_pca_traj[:,0])\n",
    "    l = len(states_A_pca_traj)\n",
    "    # print(l)\n",
    "    markers = tuple(['s'] + ['o']*(l-2) + ['>'])\n",
    "    ax.set_title(f\"Trajectory with end state: {idx}\")\n",
    "    ax.plot(states_A_pca_traj[:,0], states_A_pca_traj[:,1], states_A_pca_traj[:,2], color=\"blue\", label=\"Player A\")#, marker=markers)\n",
    "    ax.plot(states_B_pca_traj[:,0], states_B_pca_traj[:,1], states_B_pca_traj[:,2], color=\"red\", label =\"Player B\")#, marker=markers)\n",
    "\n",
    "    for j in range(len(traj)):\n",
    "        if j == 0:\n",
    "            label = \"stop\"\n",
    "        elif j == (len(traj) - 1):\n",
    "            label =\"start\"\n",
    "        else:\n",
    "            label = None\n",
    "            \n",
    "        ax.scatter(states_A_pca_traj[j,0], states_A_pca_traj[j,1], states_A_pca_traj[j,2], color=\"blue\", marker=markers[j])#, label=label)\n",
    "        ax.scatter(states_B_pca_traj[j,0], states_B_pca_traj[j,1], states_B_pca_traj[j,2], color=\"red\", marker=markers[j])#, label=label)\n",
    "        ax.legend()\n",
    "    # ax.show()\n",
    "    plot_or_show(fig,\"trajectories\"+\"_\"+str(i), \"TRAJECTORIES\")\n",
    "    # fig.savefig(os.path.join(\"figures\", \"trajectories\", \".pdf\"), format = \"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmax = df.Time.max()\n",
    "H1 = plt.scatter(df.Time, df.Reward,color=(0,0,1,.7), label=\"States reached\")\n",
    "score_means = df.groupby(\"Time\").mean().Reward\n",
    "# print(score_means)\n",
    "plt.ylabel(\"$S(\\\\theta)$\")\n",
    "plt.xlabel(\"$t$\")\n",
    "\n",
    "H3 = plt.plot(range(Tmax+1),score_means, color=(1,0,1,1), ls=\"-\",lw=1, label=\"Average value in timestep\")\n",
    "flag = True\n",
    "for traj in trajectories:\n",
    "    traj_scores = df[df.Node_id.isin(traj)].Reward\n",
    "    # print(traj)\n",
    "    # print(traj_scores)\n",
    "    if flag:\n",
    "        H2 = plt.plot(range(Tmax+1), traj_scores, color=(0,0,1,.5), ls=\"--\", lw=.5, label=\"parent-child connection\")\n",
    "    else:\n",
    "        H2 = plt.plot(range(Tmax+1), traj_scores, color=(0,0,1,.5), ls=\"--\", lw=.5)\n",
    "    flag = False\n",
    "plt.legend()\n",
    "# plt.legend([H1,H2,H3])\n",
    "plt.savefig(\"figures/winprob_t.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_col = []\n",
    "for n in df.Node_id:\n",
    "    num_children = len(df[df.Parent_id == n].index)\n",
    "    child_col.append(num_children)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exjobbvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
